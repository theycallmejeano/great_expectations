{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build a `RuleBasedProfiler`\n",
    "* This Notebook will demonstrate the steps we need to take to generate a simple `RuleBasedProfiler` by initializing the components in memory.\n",
    "\n",
    "* We will start from a new Great Expectations Data Context (ie `great_expectations` folder after running `great_expectations init`), and begin by adding the Datasource, and progressively adding more components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "\n",
    "from ruamel import yaml\n",
    "\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "\n",
    "from great_expectations.rule_based_profiler.rule.rule import Rule\n",
    "from great_expectations.rule_based_profiler.rule_based_profiler import RuleBasedProfiler, RuleBasedProfilerResult\n",
    "\n",
    "from great_expectations.rule_based_profiler.domain_builder import (\n",
    "    DomainBuilder,\n",
    "    ColumnDomainBuilder,\n",
    ")\n",
    "from great_expectations.rule_based_profiler.parameter_builder import (\n",
    "    MetricMultiBatchParameterBuilder,\n",
    ")\n",
    "from great_expectations.rule_based_profiler.expectation_configuration_builder import (\n",
    "    DefaultExpectationConfigurationBuilder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context: ge.DataContext = ge.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up: Adding `taxi_data` `Datasource`\n",
    "* Add `taxi_data` as a new `Datasource`\n",
    "* We are using an `InferredAssetFilesystemDataConnector` to connect to data in the `test_sets/taxi_yellow_tripdata_samples` folder and get one `DataAsset` (`yellow_tripdata_sample_2018`) that has 12 Batches (1 Batch/month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path: str = \"../../../../test_sets/taxi_yellow_tripdata_samples\"\n",
    "\n",
    "datasource_config = {\n",
    "    \"name\": \"taxi_multi_batch_datasource\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"PandasExecutionEngine\",\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"default_inferred_data_connector_name\": {\n",
    "            \"class_name\": \"InferredAssetFilesystemDataConnector\",\n",
    "            \"base_directory\": data_path,\n",
    "            \"default_regex\": {\n",
    "                \"group_names\": [\"data_asset_name\", \"month\"],\n",
    "                \"pattern\": \"(yellow_tripdata_sample_2018)-(\\\\d.*)\\\\.csv\",\n",
    "            },\n",
    "        },\n",
    "        \"default_inferred_data_connector_name_all_years\": {\n",
    "            \"class_name\": \"InferredAssetFilesystemDataConnector\",\n",
    "            \"base_directory\": data_path,\n",
    "            \"default_regex\": {\n",
    "                \"group_names\": [\"data_asset_name\", \"year\", \"month\"],\n",
    "                \"pattern\": \"(yellow_tripdata_sample)_(\\\\d.*)-(\\\\d.*)\\\\.csv\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "data_context.test_yaml_config(yaml.dump(datasource_config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_datasource only if it doesn't already exist in our configuration\n",
    "try:\n",
    "    data_context.get_datasource(datasource_config[\"name\"])\n",
    "except ValueError:\n",
    "    data_context.add_datasource(**datasource_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchRequests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this example, we will be using two `BatchRequests` using our `Datasource`. \n",
    "   * `single_batch_batch_request` : which gives the most recent (December) data from the 2018 `taxi_data` dataset. \n",
    "   * `multi_batch_batch_request`: which gives all 12 Batches of data from the 2018 `taxi_data` datataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_datasource\",\n",
    "    data_connector_name=\"default_inferred_data_connector_name\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2018\",\n",
    "    data_connector_query={\"index\": -1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_datasource\",\n",
    "    data_connector_name=\"default_inferred_data_connector_name\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2018\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1:  `RuleBasedProfiler` with just a `DomainBuilder` and `ExpectationConfigurationBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a `DomainBuilder`\n",
    "\n",
    "In the process of building a `RuleBasedProfiler`, one of the first components we want to build/test\n",
    "is a `DomainBuilder`, which returns the Domains (tables, columns, set of columns, etc) that the our resulting `Expectations` will be run on. In our example, the `DomainBuilder` will output a list of columns that follow a certain pattern, namely have `'_amount'` in their suffix. To this end we will be using a `ColumnDomainBuilder` which allows you to choose columns based on their suffix, name, or semantic type (like numeric or string) and our `DomainBuilder` will output a list of 4 columns : `fare_amount`, `tip_amount`, `tolls_amount` and `total_amount`.\n",
    "\n",
    "The `RuleBasedProfiler` also contains additional `DomainBuilders` that allow you to do more sophisticated filtering on your data. \n",
    "\n",
    "These include:\n",
    " * `CategoricalColumnDomainBuilder`: which allows you to choose columns based on their cardinality (number of unique values).\n",
    " * `MapMetricColumnDomainBuilder`: which allows you to choose columns based on Map Metrics, which give a yes/no answer for individual values or rows. \n",
    "\n",
    "In addition, there are `DomainBuilders` that do not perform any additional filtering, but are required by the Expectations that are being built by the `RuleBasedProfiler`. \n",
    " * `TableDomainBuilder`:  Outputs Table Domain, which is required by `Expectations` that act on tables, like (`expect_table_row_count_to_equal`, or `expect_table_columns_to_match_set`). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ColumnDomainBuilder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    include_column_name_suffixes=[\"_amount\"],\n",
    "    data_context=data_context,\n",
    ")\n",
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that the domains we get are the ones we expect\n",
    "assert len(domains) == 4\n",
    "assert domains == [\n",
    "    {\"rule_name\": \"my_rule\", \"domain_type\": \"column\", \"domain_kwargs\": {\"column\": \"fare_amount\"}, \"details\": {\"inferred_semantic_domain_type\": {\"fare_amount\": \"numeric\",}},},\n",
    "    {\"rule_name\": \"my_rule\", \"domain_type\": \"column\", \"domain_kwargs\": {\"column\": \"tip_amount\"}, \"details\": {\"inferred_semantic_domain_type\": {\"tip_amount\": \"numeric\",}},},\n",
    "    {\"rule_name\": \"my_rule\", \"domain_type\": \"column\", \"domain_kwargs\": {\"column\": \"tolls_amount\"}, \"details\": {\"inferred_semantic_domain_type\": {\"tolls_amount\": \"numeric\",}},},\n",
    "    {\"rule_name\": \"my_rule\", \"domain_type\": \"column\", \"domain_kwargs\": {\"column\": \"total_amount\"}, \"details\": {\"inferred_semantic_domain_type\": {\"total_amount\": \"numeric\",}},},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue our example, we will continue building a `RuleBasedProfiler` using our `ColumnDomainBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build `Rule`\n",
    "* The first `Rule` that we build will output `expect_column_values_to_not_be_null` because it does not take in  additional information other than Domain. We will add `ParameterBuilders` in a subsequent example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_expectation_configuration_builder = DefaultExpectationConfigurationBuilder(\n",
    "    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "    column=\"$domain.domain_kwargs.column\", # Get the column from domain_kwargs that are retrieved from the DomainBuilder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rule: Rule = Rule(\n",
    "    name=\"rule_with_no_parameters\",\n",
    "    variables=None,\n",
    "    domain_builder=domain_builder,\n",
    "    expectation_configuration_builders=[default_expectation_configuration_builder],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `RuleBasedProfiler` and add `Rule`\n",
    "* We create a simple `RuleBasedProfiler` and add the `Rule` that we added in the previous step is added to the Profiler. When we run the Profiler, the output is an `ExpectationSuite` with 4 `Expectations`, which we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.core import ExpectationSuite\n",
    "from great_expectations.rule_based_profiler.rule_based_profiler import RuleBasedProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp: RuleBasedProfiler = RuleBasedProfiler(\n",
    "    name=\"my_simple_rbp\", data_context=data_context, config_version=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp.add_rule(rule=simple_rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_result: RuleBasedProfilerResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_result = my_rbp.run(batch_request=single_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(profiler_result.expectation_configurations) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_result.expectation_configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected our simple `RuleBasedProfiler` will output 4 `Expectations`, one for each of our 4 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: `RuleBasedProfiler` with `DomainBuilder`, `ParameterBuilder` `ExpectationConfigurationBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a DomainBuilder\n",
    "* Using the same `ColumnDomainBuilder` from our previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    include_column_name_suffixes=[\"_amount\"],\n",
    "    data_context=data_context,\n",
    ")\n",
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a `ParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ParameterBuilders` help calcluate \"reasonable\" parameters for Expectations based on data that is specified by a `BatchRequest`.\n",
    "\n",
    "The largest categories include: \n",
    "- `metric_multi_batch_parameter_builder`: Which is able to calculate a numeric Metric (like `column.min`) across multiple Batches (or just one Batch).\n",
    "- `value_set_multi_batch_parameter_builder`: Which is able to build a value set across multiple Batches (or just one Batch). \n",
    "\n",
    "In some cases, there is a better way to build a value set using regex or dates. \n",
    "- `regex_pattern_string_parameter_builder`: Which contains a set of default regex patterns and builds a value set of the best-matching patterns. Users are also able to pass in new patterns as a parameter. \n",
    "- `simple_date_format_string_parameter_builder`: Which contains a set of default datetime-format patterns and builds a value set of the best-matching patterns. Users are also able to pass in new patterns as a parameter. \n",
    "\n",
    "Across multiple-Batches, we can build more-sophisticated parameters by using sampling methods. \n",
    "- `numeric_range_multi_batch_parameter_builder`: Which is able to provide range estimations across Batches using sampling methods. For instance, if we expect a table's `row_count` to change between Batches, we could calculate the min / max values of row_count by using the `NumericMetricRangeMultiBatchParameterBuilder`. These parameters could then be used by `ExpectTableRowCountToBeBetween`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example we will be using a `MetricMultiBatchParameterBuilder` to estimate the `column.min` Metric for the 4 columns defined by our Domain Builder. These are passed in as `metric_domain_kwargs` and are accessible using the fully qualified parameter `$domain.domain_kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_range_parameter_builder: MetricMultiBatchParameterBuilder = (\n",
    "    MetricMultiBatchParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        metric_name=\"column.min\",\n",
    "        metric_domain_kwargs=\"$domain.domain_kwargs\",  # domain kwarg values are accessible using fully qualified parameters\n",
    "        name=\"my_column_min\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an ExpectationConfigurationBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ExpectationConfigurationBuilder` is being built for `expect_column_values_to_be_greater_than` which will use the `column.min` values that are calculated using the `ParameterBuilder`. These are now accessible using the fully qualified parameter `$parameter.my_column_min.value[-1]`.  The `[-1]` indicates that we will use the min value from the latest Batch (the only `Batch` in this case since our `BatchRequest` only returns a single `Batch`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder: DefaultExpectationConfigurationBuilder = (\n",
    "    DefaultExpectationConfigurationBuilder(\n",
    "        expectation_type=\"expect_column_values_to_be_greater_than\",\n",
    "        value=\"$parameter.my_column_min.value[-1]\", # the parameter is accessible using a fully qualified parameter\n",
    "        column=\"$domain.domain_kwargs.column\", # domain kwarg values are accessible using fully qualified parameters\n",
    "        name=\"my_column_min\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a `Rule`, `RuleBasedProfiler`, and run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a rule with our `ParameterBuilder`, `DomainBuilder` and `ExpectationConfigurationBuilder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rule: Rule = Rule(\n",
    "    name=\"rule_with_parameters\",\n",
    "    variables=None,\n",
    "    domain_builder=domain_builder,\n",
    "    parameter_builders=[numeric_range_parameter_builder],\n",
    "    expectation_configuration_builders=[config_builder],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp = RuleBasedProfiler(name=\"my_rbp\", data_context=data_context, config_version=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the `Rule` to our `RuleBasedProfiler` and run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp.add_rule(rule=simple_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_result = my_rbp.run(batch_request=single_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(profiler_result.expectation_configurations) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_result.expectation_configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `ExpectationSuite` now contain values (`-80.0`, `0.0` etc) that were calculated from the Batch of data defined by the `BatchRequest`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: `RuleBasedProfiler` with multiple `ParameterBuilders`, `ExpectationConfigurationBuilders` and  `Variables`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third example is more complex, using multiple batches, multiple `ParameterBuilders`, `ExpectationConfigurationBuilders` and also introducing the use of `variables`.\n",
    "\n",
    "The goal of this example is to build a `RuleBasedProfiler` that outputs an `ExpectationSuite` containing 2 Expectation types\n",
    "- `expect_column_min_to_be_between` : Defined as \"Expect the column minimum to be between a min and max value\".\n",
    "- `expect_column_max_to_be_between` : Defined as \"Expect the column maxmimum to be between a min and max value\".\n",
    "\n",
    "for 2 columns in our `taxi_data` dataset\n",
    "- `fare_amount` \n",
    "- `tip_amount`\n",
    "\n",
    "with the `min_value` and `max_value` parameters for each of the Expectations estimated over 12 Batches of `taxi_data`, for a total of 4 Expectations.\n",
    "\n",
    "To estimate the parameters, we will be using a `NumericMetricRangeMultiBatchParameterBuilder`, which is able to provide range estimations across Batches using sampling methods.  We will also be using a `variables` dictionary to share defined variables across Rule components like `DomainBuilders`, `ParameterBuilders` and `ExpectationConfigurationBuilders`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `variables` dictionary\n",
    "\n",
    "`RuleBasedProfilers` allow for the definition of variables, which can be shared across Rules and Rule components. When building a complex `RuleBasedProfiler` with multiple Rules or components, using variables will help you keep track of values without having to input them multiple times.\n",
    "\n",
    "Once loaded into the `RuleBasedProfiler` configuration, the variables are accessible using the fully qualified variable name `$variables.[key_in_variables_dictionary]`, similar to how domain kwarg values and parameter values are accessible using a fully qualified name that begins with `$`.\n",
    "\n",
    "In the example below, the `estimator_name` is accessible using `$variables.estimator_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables: dict = {\n",
    "    \"multi_batch_batch_request\": multi_batch_batch_request,\n",
    "    \"estimator_name\": \"bootstrap\",\n",
    "    \"false_positive_rate\": 5.0e-2, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `RuleBasedProfiler` with `variables`\n",
    "\n",
    "Pass the `variables` dictionary into the `RuleBasedProfiler` constructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp = RuleBasedProfiler(name=\"my_complex_rbp\", data_context=data_context, variables=variables, config_version=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `ColumnDomainBuilder`\n",
    "\n",
    "The `ColumnDomainBuilder` is instantiated using column names `tip_amount` and `fare_amount`. The BatchRequest is passed in as a `$variable`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import ColumnDomainBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    include_column_names=[\"tip_amount\", \"fare_amount\"],\n",
    "    data_context=data_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `ParameterBuilders`\n",
    "\n",
    "Our Rule will contain 2 `NumericMetricRangeMultiBatchParameterBuilders`, one for each of our 2 Expectation types. One will be estimating the Parameter values for the `column.min` Metric, and the other will be estimating Parameter values for the `column.max` Metric.  `metric_domain_kwargs` are passed in from our DomainBuilder using `$domain.domain_kwargs`.\n",
    "\n",
    "Also note the use of 3 Variables we defined above: \n",
    "\n",
    "- `$variables.estimator_name`: This is `\"oneshot\"` in our case. \n",
    "- `$variables.false_positive_rate`: This is `5.0e-2` or 5% in our case.\n",
    "- `$variables.multi_batch_batch_request`: This the `multi_batch_batch_request`, which gives all 12 Batches of data from the 2018 taxi_data datataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import NumericMetricRangeMultiBatchParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_range_parameter_builder: NumericMetricRangeMultiBatchParameterBuilder = NumericMetricRangeMultiBatchParameterBuilder(\n",
    "    name=\"min_range_parameter_builder\",\n",
    "    metric_name=\"column.min\",\n",
    "    metric_domain_kwargs=\"$domain.domain_kwargs\",\n",
    "    false_positive_rate='$variables.false_positive_rate',\n",
    "    estimator=\"$variables.estimator_name\",\n",
    "    data_context=data_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_range_parameter_builder: NumericMetricRangeMultiBatchParameterBuilder = NumericMetricRangeMultiBatchParameterBuilder(\n",
    "    name=\"max_range_parameter_builder\",\n",
    "    metric_name=\"column.max\",\n",
    "    metric_domain_kwargs=\"$domain.domain_kwargs\",\n",
    "    false_positive_rate=\"$variables.false_positive_rate\",\n",
    "    estimator=\"$variables.estimator_name\",\n",
    "    data_context=data_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `ExpectationConfigurationBuilders`\n",
    "\n",
    "Our Rule will contain 2 `ExpectationConfigurationBuilders`, one for each of our 2 Expectation types: \n",
    "\n",
    "- `expect_column_min_to_be_between`\n",
    "- `expect_column_max_to_be_between`\n",
    "\n",
    "The Expectations are both `ColumnExpectations`, so the `column` parameter will be accessed from the Domain kwargs using `$domain.domain_kwargs.column`. \n",
    "\n",
    "The Expectations also take in a `min_value` and `max_value` parameter, which our `NumericMetricRangeMultiBatchParameterBuilders` are estimating. For `expect_column_min_to_be_between`, these estimated values are accessible using\n",
    "\n",
    "- `$parameter.min_range_parameter_builder.value[0]` for the `min_value`, with `min_range_parameter_builder` being the name of our ParameterBuilder that estimates the `column.min` metric.\n",
    "- `$parameter.min_range.value[1]` for the `max_value`.\n",
    "\n",
    "The equivalent `$parameter` for `expect_column_max_to_be_between` would be `$parameter.max_range.value[0]` and `$parameter.max_range_parameter_builder.value[1]` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_column_min: DefaultExpectationConfigurationBuilder = DefaultExpectationConfigurationBuilder(\n",
    "    expectation_type=\"expect_column_min_to_be_between\",\n",
    "    column=\"$domain.domain_kwargs.column\",\n",
    "    min_value=\"$parameter.min_range_parameter_builder.value[0]\",\n",
    "    max_value=\"$parameter.min_range_parameter_builder.value[1]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_column_max: DefaultExpectationConfigurationBuilder = DefaultExpectationConfigurationBuilder(\n",
    "    expectation_type=\"expect_column_max_to_be_between\",\n",
    "    column=\"$domain.domain_kwargs.column\", \n",
    "    min_value=\"$parameter.max_range_parameter_builder.value[0]\",\n",
    "    max_value=\"$parameter.max_range_parameter_builder.value[1]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `RuleBasedProfiler` and Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a Rule with our `DomainBuilder`, `ParameterBuilders` and `ExpectationConfigurationBuilders` and load into our `RuleBasedProfiler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_complex_rule: Rule = Rule(\n",
    "    name=\"rule_with_parameters\",\n",
    "    variables=None,\n",
    "    domain_builder=domain_builder,\n",
    "    parameter_builders=[min_range_parameter_builder, max_range_parameter_builder],\n",
    "    expectation_configuration_builders=[expect_column_min, expect_column_max],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp.add_rule(rule=more_complex_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_result = my_rbp.run(batch_request=multi_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_result.expectation_configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the resulting ExpectationSuite contains our minimum and maximum values, with `tip_amount` ranging from `$-2.16` to `$195.05` (a generous tip), and `fare_amount` ranging from `$-98.90` (a refund) to `$405,904.54` (a very very long trip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Appendix\n",
    "\n",
    "* Here we have additional example configuration of `DomainBuilder` and `ParameterBuilders` that were not included in the previous 3 Examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DomainBuilders`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ColumnDomainBuilder`\n",
    "This `DomainBuilder` outputs column Domains, which are required by `ColumnExpectations` like (`expect_column_median_to_be_between`). There are a few ways that the `ColumnDomainBuilder` can be used. \n",
    "\n",
    "1. In the simplest usecase, the `ColumnDomainBuilder` can output all columns in the dataset as a Domain, or include/exclude columns if you already know which ones you would like. Column suffixes (like `_amount`) can be used to select columns of interest, as we saw in our examples above.\n",
    "3. The `ColumnDomainBuilder` also allows you to choose columns based on their semantic types (such as numeric, or text).\n",
    "\n",
    "    - Semantic types are defined as an Enum object called SemanticDomainTypes, which can be found here : https://github.com/great-expectations/great_expectations/blob/develop/great_expectations/rule_based_profiler/types/domain.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import ColumnDomainBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simplest usecase, the `ColumnDomainBuilder` can output all of the columns in `yellow_tripdata_sample_2018`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    data_context=data_context,\n",
    ")\n",
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)\n",
    "assert len(domains) == 18 # all columns in yellow_tripdata_sample_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns can also be included or excluded by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    include_column_names=[\"vendor_id\"],\n",
    "    data_context=data_context,\n",
    ")\n",
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)\n",
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    exclude_column_names=[\"vendor_id\"],\n",
    "    data_context=data_context,\n",
    ")\n",
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)\n",
    "assert len(domains) == 17 # all columns in yellow_tripdata_sample_2018 with vendor_id excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, the `ColumnDomainBuilder` also allows you to choose columns based on their semantic types (such as numeric, or text). This is passed in as part of the `include_semantic_types` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    include_semantic_types=['numeric'],\n",
    "    data_context=data_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)\n",
    "assert len(domains) == 15 # columns in yellow_trip_data_sample_2018 that are numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`MultiColumnDomainBuilder`**\n",
    "\n",
    "This DomainBuilder outputs `multicolumn` Domains by taking in a column list in the `include_column_names` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import MultiColumnDomainBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = MultiColumnDomainBuilder(\n",
    "    include_column_names=[\"vendor_id\", \"fare_amount\", \"tip_amount\"],\n",
    "    data_context=data_context,\n",
    ")\n",
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)\n",
    "assert len(domains) == 1 # 3 columns are part of a single multi-column domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_columns: list = [\"vendor_id\", \"fare_amount\", \"tip_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert domains[0][\"domain_kwargs\"][\"column_list\"] == expected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ColumnPairDomainBuilder`**\n",
    "\n",
    "This DomainBuilder outputs columnpair domains by taking in a column pair list in the include_column_names parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import ColumnPairDomainBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = ColumnPairDomainBuilder(\n",
    "    include_column_names=[\"vendor_id\", \"fare_amount\"],\n",
    "    data_context=data_context,\n",
    ")\n",
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)\n",
    "assert len(domains) == 1 # 2 columns are part of a single multi-column domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_columns_dict: dict = {'column_A': 'fare_amount', 'column_B': 'vendor_id'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert domains[0][\"domain_kwargs\"] == expect_columns_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TableDomainBuilder`\n",
    "This `DomainBuilder` outputs table `Domains`, which is required by `Expectations` that act on tables, like (`expect_table_row_count_to_equal`, or `expect_table_columns_to_match_set`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import TableDomainBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = TableDomainBuilder(\n",
    "    data_context=data_context,\n",
    ")\n",
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)\n",
    "domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MapMetricColumnDomainBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `DomainBuilder` allows you to choose columns based on Map Metrics, which give a yes/no answer for individual values or rows. In this example, we use the Map Metrics `column_values.nonnull` to filter out a column that was all `None` from `taxi_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import MapMetricColumnDomainBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = MapMetricColumnDomainBuilder(\n",
    "    map_metric_name=\"column_values.nonnull\",\n",
    "    data_context=data_context,\n",
    ")\n",
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)\n",
    "len(domains) == 17 # filtered 1 column that was all None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `CategoricalColumnDomainBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `DomainBuilder` allows you to choose columns based on their cardinality (number of unique values).The `CategoricalColumnDomainBuilder` will take in various `cardinality_limit_mode` values for cardinality, and in this example we are only interested in columns that have \"very_few\" (less than 10) unique values. For a full of valid modes, along with the associated values, please refer to the `CardinalityLimitMode` enum in:\n",
    "\n",
    "https://github.com/great-expectations/great_expectations/blob/develop/great_expectations/rule_based_profiler/helpers/cardinality_checker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import CategoricalColumnDomainBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = CategoricalColumnDomainBuilder(\n",
    "    cardinality_limit_mode=\"very_few\", # VERY_FEW = 10 or less\n",
    "    data_context=data_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domains: list = domain_builder.get_domains(rule_name=\"my_rule\", batch_request=single_batch_batch_request)\n",
    "assert len(domains) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ParameterBuilders`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ParameterBuilders` work under the hood by populating a `ParameterContainer`, which can also be shared by multiple `ParameterBuilders`. It requires a Domain, and `metric_name`, with `domain_kwargs` accessible from the `DomainBuilder` using the fully qualified parameter `$domain.domain_kwargs`.\n",
    "\n",
    "For the sake of simplicity, we will define a `Domain` object directly using the `Domain()` constructor, and pass in a column name within `domain_kwargs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.types.domain import Domain\n",
    "from great_expectations.core.metric_domain_types import MetricDomainTypes\n",
    "from great_expectations.rule_based_profiler.types import ParameterContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain: Domain = Domain(rule_name=\"my_rule\", domain_type=MetricDomainTypes.COLUMN, domain_kwargs = {'column': 'total_amount'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MetricMultiBatchParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MetricMultiBatchParameterBuilder` computes a Metric on data from one or more batches. It takes `domain_kwargs`, `value_kwargs`, and `metric_name` as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import MetricMultiBatchParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_range_parameter_builder: MetricMultiBatchParameterBuilder = (\n",
    "    MetricMultiBatchParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        metric_name=\"column.min\",\n",
    "        metric_domain_kwargs=domain.domain_kwargs,\n",
    "        name=\"my_column_min\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_container: ParameterContainer = ParameterContainer(parameter_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    domain.id: parameter_container,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_range_parameter_builder.build_parameters(\n",
    "    domain=domain,\n",
    "    parameters=parameters,\n",
    "    batch_request=multi_batch_batch_request,\n",
    ")\n",
    "# we check the parameter container\n",
    "print(parameter_container.parameter_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(parameter_container.parameter_nodes[\"parameter\"][\"parameter\"][\"my_column_min\"][\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`my_column_min[value]` now contains a list of 12 values, which are the minimum values the `total_amount` column for each of the 12 Batches associated with 2018 `taxi_data` data. If we were to use the values in a `ExpectationConfigurationBuilder`, it would be accessible through the fully-qualified parameter: `$parameter.my_column_min.value`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ValueSetMultiBatchParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ValueSetMultiBatchParameterBuilder` is able to build a value set across multiple Batches (or just one Batch). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import ValueSetMultiBatchParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain: Domain = Domain(rule_name=\"my_rule\", domain_type=MetricDomainTypes.COLUMN, domain_kwargs = {'column': 'vendor_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a new parameter container, since it can contain the results of more than one ParmeterBuilder. \n",
    "parameter_container: ParameterContainer = ParameterContainer(parameter_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters[domain.id] = parameter_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_set_parameter_builder: ValueSetMultiBatchParameterBuilder = (\n",
    "    ValueSetMultiBatchParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        metric_domain_kwargs=domain.domain_kwargs,\n",
    "        name=\"my_value_set\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value_set_parameter_builder.build_parameters(\n",
    "    domain=domain,\n",
    "    parameters=parameters,\n",
    "    batch_request=multi_batch_batch_request,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parameter_container.parameter_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`my_value_set[value]` now contains a list of 3 values, which is a list of all unique `vendor_ids` across 12 Batches in the 2018 `taxi_data` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `RegexPatternStringParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RegexPatternStringParameterBuilder` contains a set of default regex patterns and builds a value set of the best-matching patterns. Users are also able to pass in new patterns as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import RegexPatternStringParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain: Domain = Domain(rule_name=\"my_rule\", domain_type=MetricDomainTypes.COLUMN, domain_kwargs = {'column': 'vendor_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `vendor_id` is a single integer. Let's see if our default patterns can match it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_container: ParameterContainer = ParameterContainer(parameter_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters[domain.id] = parameter_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_parameter_builder: RegexPatternStringParameterBuilder = (\n",
    "    RegexPatternStringParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        metric_domain_kwargs=domain.domain_kwargs,\n",
    "        name=\"my_regex_set\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_parameter_builder.build_parameters(\n",
    "    domain=domain,\n",
    "    parameters=parameters,\n",
    "    batch_request=single_batch_batch_request,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parameter_container.parameter_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looks like `my_regex_set[value]` is an empty list. This means that none of the `evaluated_regexes` matched our domain. Let's try the same thing again, but this time with a regex that will match our `vendor_id` column. `^\\\\d{1}$` and `^\\\\d{2}$` which will match 1 or 2 digit integers anchored at the beginning and end of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_parameter_builder: RegexPatternStringParameterBuilder = (\n",
    "    RegexPatternStringParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        metric_domain_kwargs=domain.domain_kwargs,\n",
    "        candidate_regexes=[\"^\\\\d{1}$\"],\n",
    "        name=\"my_regex_set\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_parameter_builder.build_parameters(\n",
    "    domain=domain,\n",
    "    parameters=parameters,\n",
    "    batch_request=single_batch_batch_request,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parameter_container.parameter_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now `my_regex_set[value]` contains `^\\\\d{1}$`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `SimpleDateFormatStringParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SimpleDateFormatStringParameterBuilder` contains a set of default Datetime format patterns and builds a value set of the best-matching patterns. Users are also able to pass in new patterns as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import SimpleDateFormatStringParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain: Domain = Domain(rule_name=\"my_rule\", domain_type=MetricDomainTypes.COLUMN, domain_kwargs = {'column': 'pickup_datetime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_container: ParameterContainer = ParameterContainer(parameter_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters[domain.id] = parameter_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_date_format_string_parameter_builder: SimpleDateFormatStringParameterBuilder = (\n",
    "    SimpleDateFormatStringParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        metric_domain_kwargs=domain.domain_kwargs,\n",
    "        name=\"my_value_set\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_date_format_string_parameter_builder.build_parameters(\n",
    "    domain=domain,\n",
    "    parameters=parameters,\n",
    "    batch_request=single_batch_batch_request,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parameter_container.parameter_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_container.parameter_nodes[\"parameter\"][\"parameter\"][\"my_value_set\"][\"value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result contains our matching `datetime` pattern, which is `'%Y-%m-%d %H:%M:%S'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `NumericMetricRangeMultiBatchParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NumericMetricRangeMultiBatchParameterBuilder` is able to provide range estimations across Batches using sampling methods. For instance, if we expect a table's row_count to change between Batches, we could calculate the min / max values of row_count by using the `NumericMetricRangeMultiBatchParameterBuilder`. These parameters could then be used by `Expectations` that take in ranges, like `ExpectTableRowCountToBeBetween`, or `ExpectColumnValuesToBeBetween`.\n",
    "\n",
    "In this example, we will be taking a single Metric, `column.mean` and calculating it for a single column, `total_amount`. The parameter we will be building is the column mean-range, which are the min-max values of the `total_amount` column across random samples of 12 Batches of the 2018 `taxi_data` dataaset. \n",
    "\n",
    "We will also be passing in specifications for estimator, namely `bootstrap` sampling with a false-positive rate of less than 0.01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import NumericMetricRangeMultiBatchParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain: Domain = Domain(rule_name=\"my_rule\", domain_type=MetricDomainTypes.COLUMN, domain_kwargs = {'column': 'total_amount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_container: ParameterContainer = ParameterContainer(parameter_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters[domain.id] = parameter_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_metric_range_parameter_builder: NumericMetricRangeMultiBatchParameterBuilder = NumericMetricRangeMultiBatchParameterBuilder(\n",
    "    name=\"column_mean_range\",\n",
    "    metric_name=\"column.mean\",\n",
    "    estimator=\"bootstrap\",\n",
    "    metric_domain_kwargs=domain.domain_kwargs,\n",
    "    false_positive_rate=1.0e-2,\n",
    "    round_decimals=0,\n",
    "    data_context=data_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_metric_range_parameter_builder.build_parameters(\n",
    "    domain=domain,\n",
    "    parameters=parameters,\n",
    "    batch_request=multi_batch_batch_request,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parameter_container.parameter_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the mean value range for the `total_amount` column is `16.0` to `44.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Clean-up Directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of running this notebook, the `RuleBasedProfiler` will create a number of ExpectationSuite configurations in the `great_expectations/expectations/tmp` directory. Optionally run the following cell to clean up the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shutil\n",
    "# clean up Expectations directory after running tests\n",
    "#shutil.rmtree(\"great_expectations/expectations/tmp\")\n",
    "#os.remove(\"great_expectations/expectations/.ge_store_backend_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel-venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
